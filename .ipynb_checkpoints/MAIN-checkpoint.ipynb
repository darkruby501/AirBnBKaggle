{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN\n",
    "This is the master notebook for my AirBnB Recruiting Challenge work. Changes and additions are made by branching and merging.\n",
    "\n",
    "Other possible branches:\n",
    "* Explore\n",
    "* Prepocessing\n",
    "* Features\n",
    "* Models\n",
    "* Multiclass\n",
    "* Imbalance\n",
    "* Validation\n",
    "* Ensembels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Draw inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set figure aesthetics\n",
    "sns.set_style(\"whitegrid\") #, {'ytick.major.size': 10.0})\n",
    "#sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data into DataFrames\n",
    "train_users = pd.read_csv('input/train_users_2.csv')\n",
    "test_users = pd.read_csv('input/test_users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prefilter Classes\n",
    "Reduce the number of classes to reduce computational costs (and maybe noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Reducing to only the top five cases retains 96% of training examples including, and 90% of examples with bookings. \n",
    "\n",
    "#included_destinations = ['NDF','US']\n",
    "included_destinations = ['NDF','US','FR','IT','other']\n",
    "\n",
    "train_users = train_users[train_users['country_destination'].apply(lambda x: x in included_destinations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_users.shape[0]\n",
    "#train_users1.shape[0]\n",
    "#train_users1.shape[0]/train_users.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Measure: NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rank_metrics import ndcg_at_k\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def ndcg_wrapper(y_true,y_pred_proba):\n",
    "    \n",
    "    Y = np.fliplr(y_pred_proba.argsort())\n",
    "        \n",
    "    R = []\n",
    "    NDCG = []\n",
    "    for i in range(0,y_true.size):\n",
    "        r = (Y[i,:]==y_true[i]).astype(int)\n",
    "        R.append(r)\n",
    "        #ndcg_at_k([0,0,1],5,method=1)\n",
    "        NDCG.append(ndcg_at_k(r,5,method=1))\n",
    "    \n",
    "    #print(NDCG)\n",
    "    #return NDCG,R\n",
    "    return np.mean(NDCG)\n",
    "\n",
    "ndcg_scorer = make_scorer(ndcg_wrapper, greater_is_better=True, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of Main Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_missing(df):\n",
    "    ##AGE\n",
    "    #Remove all ages outside of range, set to -1 for separate categorisation //impute for logistic regression\n",
    "    df.loc[df.age > 95, 'age'] = -1\n",
    "    df.loc[df.age < 13, 'age'] = -1\n",
    "    df.fillna(-1,inplace=True)\n",
    "\n",
    "    ## GENDER\n",
    "    # Set missing values to own category\n",
    "    df['gender'].replace('-unknown-',np.nan, inplace=True)\n",
    "    #df['gender'].fillna('MISSING',inplace=True)\n",
    "\n",
    "    ## FIRST AFFILIATE TRACKED\n",
    "    # Set missing to untracked, hopefully the same\n",
    "    df['first_affiliate_tracked'].fillna('untracked',inplace=True)\n",
    "    \n",
    "    ## Get rid of date_first_booking\n",
    "    df.drop(['date_first_booking'],axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_features(df):\n",
    "    ## dates\n",
    "    \n",
    "    # date_account_created\n",
    "    dac = np.vstack(df.date_account_created.astype(str).apply(lambda x: list(map(int, x.split('-')))).values)\n",
    "    df['dac_year'] = dac[:,0]\n",
    "    df['dac_month'] = dac[:,1]\n",
    "    df['dac_day'] = dac[:,2]\n",
    "    df.drop(['date_account_created'],axis=1,inplace=True)\n",
    "    \n",
    "    #time first active\n",
    "    tfa = np.vstack(df.timestamp_first_active.astype(str).apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8],x[8:10],x[10:12],x[12:14]]))).values)\n",
    "    df['tfa_year'] = tfa[:,0]\n",
    "    df['tfa_month'] = tfa[:,1]\n",
    "    df['tfa_day'] = tfa[:,2]\n",
    "    df['tfa_hour'] = tfa[:,3]\n",
    "    df.drop(['timestamp_first_active'],axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    ## One-Hot Encoding\n",
    "    categorical_features = ['affiliate_channel','affiliate_provider','first_affiliate_tracked',\n",
    "                            'first_browser','first_device_type','gender','language','signup_app','signup_flow','signup_method'\n",
    "                           ]\n",
    "    \n",
    "    df = pd.get_dummies(df,columns=categorical_features)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_all(df):\n",
    "\n",
    "    df_p = preprocess_missing(df)\n",
    "    df_p = preprocess_features(df_p)\n",
    "    \n",
    "    return(df_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_master = preprocess_all(train_users.drop(['country_destination'],axis=1))\n",
    "y_master = train_users['country_destination']\n",
    "#train_master = pd.concat([X_master,y_master],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session_df = pd.read_csv('input/sessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counts of Actions Taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session_users = session_df\n",
    "\n",
    "# Clean missing values\n",
    "session_users['secs_elapsed'].fillna(0,inplace=True)\n",
    "session_users['action_type'].fillna('',inplace=True)\n",
    "\n",
    "# Combine for grouping\n",
    "#session_users['action_action_type'] = session_users['action']+'__'+session_users['action_type']\n",
    "session_users['action_action_detail'] = session_users['action']+'__'+session_users['action_detail']\n",
    "#session_users['action_action_type_detail'] = session_users['action']+'__'+session_users['action_type']+'__'+session_users['action_detail']\n",
    "\n",
    "\n",
    "# Group actions for users\n",
    "#session_users1 = session_users.groupby(['user_id','action_action_type']).count()['secs_elapsed'].unstack().fillna(0)\n",
    "session_users2 = session_users.groupby(['user_id','action_action_detail']).count()['secs_elapsed'].unstack().fillna(0)\n",
    "#session_users3 = session_users.groupby(['user_id','action_action_type_detail']).count()['secs_elapsed'].unstack().fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#session_users2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elapsed Time by Device Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deviceusage_df = session_df[['user_id','device_type','secs_elapsed']].groupby(['user_id','device_type']).sum().unstack()['secs_elapsed']\n",
    "deviceusage_df.fillna(0,inplace=True)\n",
    "#deviceusage_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SessionFeatures = pd.merge(session_users2,deviceusage_df,right_index=True,left_index=True,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age_Gender_Bkts - Create Features\n",
    "Could also add in Country Locations here . . . if that makes a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_gender_df = pd.read_csv('input/age_gender_bkts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = pd.pivot_table(age_gender_df,values='population_in_thousands',index=['age_bucket','gender'],columns='country_destination')\n",
    "normalised_brackets = A.divide(A.sum(axis=1),axis=0)\n",
    "normalised_totals = A.sum()/A.sum().sum()\n",
    "#normalised_brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#AA = A.reset_index().groupby('gender').sum()  ## - Later separate missing by male and female . . . very sligth difference?\n",
    "#AA.loc['female']/AA.loc['male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def age_bucket_converter(age, gender):\n",
    "    \n",
    "    \n",
    "    if (age>0)&(age<100):\n",
    "        a = int((age//5)*5)\n",
    "        Age = str(a)+'-'+str(a+4)\n",
    "        if Age == '5-9': Age = 'Missing'\n",
    "        \n",
    "    elif age>99: Age = '100+'\n",
    "    else: Age = 'Missing'\n",
    "        \n",
    "    if gender == 'MALE': Gender = 'male'\n",
    "    elif gender == 'FEMALE': Gender = 'female'\n",
    "    else: Gender = 'Missing'\n",
    "    \n",
    "    return (Age, Gender)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bkts_feature_create(age_gender,normalised_brackets,normalised_totals):\n",
    "     \n",
    "    Age,Gender = age_bucket_converter(*age_gender)\n",
    "    #print([Age,Gender])\n",
    "    \n",
    "    if ((Age=='Missing')|(Gender=='Missing')):\n",
    "        return normalised_totals\n",
    "    else:\n",
    "        return normalised_brackets.loc[(Age,Gender)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Test\n",
    "# train_users.head(5)[['age','gender']].apply(lambda x: bkts_feature_create(tuple(x.values),normalised_brackets,normalised_totals),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_users.head(5)[['age','gender']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BracketFeatures = train_users[['age','gender']].apply(lambda x: bkts_feature_create(tuple(x.values),normalised_brackets,normalised_totals),axis=1)\n",
    "BracketFeatures.set_index(train_users['id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELECT AND COMBINE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_master\n",
    "y = y_master\n",
    "# Need to combine X and Y when losing rows.\n",
    "X['country_destination'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Merge with Bracket Features\n",
    "X = X.merge(BracketFeatures,how='inner',left_on='id',right_index=True) \n",
    "\n",
    "## Merge with Session Features\n",
    "#X = X.merge(SessionFeatures,how='inner',left_on='id',right_index=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = X['country_destination']\n",
    "X.drop(['country_destination','id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204871, 165)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Logistic Regression without Grid Search on gets CrossVal of 0.657, which is a mild improvement over 0.583 for setting all NDF. Balancing classes brings it down negligably to 0.646\n",
    "Grid search doesn't seemed to have helped - 0.658 with C of 11.94\n",
    "After scaling age, this now appears third largest among the coefficients, though seemingly a decrease in accuracy to 0.63\n",
    "\n",
    "Discretizing age has increased the score to 0.667, on 1% up. It's something.But none of the age variables features in important coefficients.\n",
    "Reintoducing age as continuous (with NaNs imputed) together with discrete , brings things now up to 0.675. Huh\n",
    "\n",
    "Interesting. The score on the training data is almost the same. So we might not be overfitting and just have too high bias.\n",
    "\n",
    "And now the age brackets are appearing in the coeffs. How very strange. Seems that having entered your age validly correlates with actually booking. Now gender isn't showing up though. Could there just be the single latent variable of \"filling out the form properly?\"\n",
    "\n",
    "Next run of GridSearch gives ~5 for C, stronger regularisation, and a score of 0.688, which is several points up from when I started.\n",
    "\n",
    "----------------- \n",
    "\n",
    "Changing now to multiclass, helps with developing NDCG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FR', 0), ('IT', 1), ('NDF', 2), ('US', 3), ('other', 4)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "c:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Customise Train and Test for Logistic Regression\n",
    "\n",
    "\n",
    "## DISCRETIZE\n",
    "X_log = X # Create X just for Logistic Regression\n",
    "A = pd.cut(X_log['age'],list(range(14,100,5)),right=True)\n",
    "A = pd.get_dummies(A)\n",
    "X_log= pd.concat([X_log,A],axis=1)\n",
    "#X_train.drop(['age'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "## IMPUTE VALUES AND SCALE\n",
    "\n",
    "X_log['age'].replace(-1,np.median(X_log['age']),inplace=True)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_log['age'] = scaler.fit_transform(X_log['age'])\n",
    "\n",
    "\n",
    "## Label  Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_log = le.fit_transform(y)\n",
    "print(list(zip(le.classes_,range(0,12))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf = LogisticRegressionCV(Cs=[0.0001,0.0005,0.001],class_weight='balanced') #class_weight='balanced'\n",
    "clf.fit(X_log,y_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_cv = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_cv.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndcg_scorer(clf,X_log,y_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = clf.predict_proba(X_log)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaa = list(zip(range(0,12),le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.fliplr(aa.argsort())).replace(dict(aaa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('NDCG = ',ndcg_scorer(clf,X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_log, y_log, random_state=0)\n",
    "ndcg_scorer(clf,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG =  0.838857821272\n",
      "Accuracy =  0.636924518724\n"
     ]
    }
   ],
   "source": [
    "#%%timeit -r1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C = 0.0005,class_weight='balanced')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log, y_log, random_state=0)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('NDCG = ',ndcg_scorer(clf,X_test,y_test))\n",
    "print('Accuracy = ',metrics.accuracy_score(y_test,y_pred))\n",
    "#print('Recall = ',metrics.recall_score(y_test,y_pred))\n",
    "#print('Precision = ',metrics.precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Test for overfitting:\n",
    "y_pred = clf.predict(X_train)\n",
    "print('NDCG = ',ndcg_scorer(clf,X_train,y_train))\n",
    "print('Accuracy = ',metrics.accuracy_score(y_train,y_pred))\n",
    "print('Recall = ',metrics.recall_score(y_train,y_pred))\n",
    "print('Precision = ',metrics.precision_score(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = 0.0001,class_weight='balanced')\n",
    "print(np.mean(cross_val_score(clf,X_log,y_log,cv=3,scoring=ndcg_scorer,n_jobs=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84087057228853579"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compare with basic.\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "Dummy = DummyClassifier(strategy='prior').fit(X_log,y_log)\n",
    "ndcg_scorer(Dummy,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FeatureImportances = pd.DataFrame(data = { 'coefs': clf.coef_.squeeze(), 'abs coefs' : np.abs(clf.coef_.squeeze())},index=X_log.columns)\n",
    "FeatureImportances.sort_values(by='abs coefs',ascending=False,inplace=True)\n",
    "\n",
    "k = 50\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(y=FeatureImportances.index[0:k],x=FeatureImportances['coefs'].head(k))\n",
    "#plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The picture I get from this that people are less likely to book from mobile devices. And more likely to book if they correctly filled out their from. I doubt logicst regression has handled the age feature well. Hence why discretizing might be a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Crange = np.logspace(-1,2,30)\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid={'C': Crange},scoring='accuracy',cv=3,n_jobs=4)\n",
    "grid.fit(X_train,y_train)\n",
    "print (\"best parameter choice:\", grid.best_params_)\n",
    "print (\"best score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# BELOW HERE IS MESSY - OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(y)\n",
    "y_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=50,\n",
    "                              random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "forest.fit(X_log, y_int)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_log.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_log.shape[1]), indices)\n",
    "plt.xlim([-1, X_log.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_log.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_log.shape[1]), indices)\n",
    "plt.xlim([-1, X_log.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.columns[[7,6,3,0,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform()\n",
    "y_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Let's make this binary classification.\n",
    "booked = y!='NDF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_users = train_users[pd.to_datetime(train_users)]\n",
    "X = preprocess_all(train_users.drop(['country_destination'],axis=1))\n",
    "y = train_users['country_destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Let's get a classifier going\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_log, y_log, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(Xtrain,ytrain)\n",
    "ypred = clf.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy = ',metrics.accuracy_score(ytest,ypred))\n",
    "print('Recall = ',metrics.recall_score(ytest,ypred))\n",
    "print('Precision = ',metrics.precision_score(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FeatureImportances = pd.Series(index=X_log.columns,data=clf.feature_importances_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 50\n",
    "plt.figure(figsize=(10,15))\n",
    "sns.barplot(y=FeatureImportances.index[0:k],x=FeatureImportances.head(k))\n",
    "#plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XX.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XX = pd.concat([X_log['tfa_hour'],y],axis=1)\n",
    "XX['A'] = 1\n",
    "XX['Booked'] = XX['country_destination']!='NDF'\n",
    "XX = XX.groupby(['Booked','tfa_hour']).count()\n",
    "\n",
    "sns.barplot(data=XX.reset_index(),x ='tfa_hour',y='A',hue='Booked', order = range(1,25))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "YY = XX['A'].unstack().T\n",
    "YY.columns[1]\n",
    "YY['P'] = YY[YY.columns[1]]/YY.sum(axis=1)\n",
    "YY\n",
    "sns.barplot(data=YY.reset_index(),x='tfa_hour',y='P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YY = XX.unstack(level=0).drop('country_destination',axis=1)\n",
    "YY.columns\n",
    "#YY['proportion'] = YY[A,'True']/(YY[A,'True']+YY[A,'False'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
